import numpy as npimport timefrom sklearn.metrics.pairwise import pairwise_kernelsfrom scipy.linalg import inv__all__=["KLR_gradient"]class KLR_gradient(object):    def __init__(self,X,Y,lamda=1,kernel="rbf",learning_rate=0.01):                # X n*d data matrix        # Y n labels        assert X.shape[0]==Y.shape[0]                        self._kernel=kernel        self._X=X        self._Y=Y        self._lamda=lamda        self._dim=X.shape[1]        self._n=X.shape[0]        self._learning_rate=learning_rate        self._alpha=np.random.rand(self._n)                self._precision=1e-4                        #self.prediction=np.zeros(self._n)        self.loss=0        self.iteration=0        self._losssave=1e8        self.train_time=0                    @staticmethod    def kernel_matrix(X,kernel,X_test=None):        if X_test is not None:            K=pairwise_kernels(X,X_test, metric=kernel)        else:            K=pairwise_kernels(X, metric=kernel)                    return K            #@staticmethod    #def compute_KWK(K,n,W):    #    return ((K[:,None].reshape(n,n,1)*K[:,None])*W.reshape(n,1,1)).sum(axis=0)        @staticmethod    def sigmoid(X):                return .5 * (1 + np.tanh(.5 * X))        @classmethod    def W(cls,K,alpha):        #print( np.matmul(alpha,SK))        p=cls.sigmoid( np.matmul(alpha,K))        #sigma=cls.sigmoid( Y*np.matmul(alpha,SK))        #W=p-p**2                return p                @classmethod    def cost(cls,K, Y, alpha):        return -np.log(cls.sigmoid(Y*( np.matmul(K,alpha)))+1e-8 ).sum()                        def fit(self):                # fit kernel        self._K=self.kernel_matrix(self._X,self._kernel)                time_start=time.time()        while(abs(self._losssave-self.loss)>self._precision):                        self.iteration+=1            if self.iteration>100:                self._learning_rate=0.001            self._losssave=self.loss            p=self.W(self._K,self._alpha)            #print(self.loss)            #KWK=self.compute_KWK(np.transpose(self._K),self._n,W)                                    #if np.linalg.matrix_rank(SKWKS+self._lamda*self._SKS)<self._m:                #print(self._SKS.shape)                #print(self._m)                #print(np.linalg.matrix_rank(self._SKS))                #print(np.linalg.matrix_rank(SKWKS))                #print(np.linalg.matrix_rank(SKWKS+self._lamda*self._SKS))                            left=np.matmul(self._K*(p-1),self._Y)            right=self._lamda*np.matmul(self._K,self._alpha)            #inv_part=inv(self._K*W+self._lamda*np.diag(np.ones(self._n)))            #add_part=np.matmul(W.reshape(-1,1)*self._K,self._alpha)+self._Y*(1-p)                                    self._alpha=self._alpha-self._learning_rate*(left+right)            self.loss=self.cost(np.transpose(self._K),self._Y,self._alpha)                    time_end=time.time()        self.train_time=time_end-time_start        self.train_probability=p                                    def predict(self,X_test):        time_start=time.time()        self._X_test=X_test        self._K_test=self.kernel_matrix(self._X,self._kernel,self._X_test)                                            self.test_probability=self.sigmoid(np.matmul(self._alpha,self._K_test))        self.prediction=(self.test_probability>0.5)*2-1                time_end=time.time()        self.test_time=time_end-time_start                                                